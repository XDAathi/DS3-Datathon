{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e434519c-8e4d-4e91-a55a-680e1231c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#read file\n",
    "df = pd.read_csv(\"car_eval_train.csv\")\n",
    "df_test = pd.read_csv(\"car_eval_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bf698",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15ad0ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id buying  maint doors persons lug_boot safety\n",
       "0   0    low  vhigh     3    more      big   high\n",
       "1   1    med    med     4       2      big   high\n",
       "2   2    med    low     2    more      big   high\n",
       "3   3    med    low     3       4    small    med\n",
       "4   4   high    low     2       4      med    low"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21647221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
      "buying: \n",
      "['med' 'low' 'vhigh' 'high']\n",
      "maint: \n",
      "['med' 'high' 'low' 'vhigh']\n",
      "doors: \n",
      "['3' '5more' '2' '4']\n",
      "persons: \n",
      "['4' '2' 'more']\n",
      "lug_boot: \n",
      "['med' 'small' 'big']\n",
      "safety: \n",
      "['med' 'high' 'low']\n"
     ]
    }
   ],
   "source": [
    "names = list(df.columns.values[:-1])\n",
    "print(names)\n",
    "\n",
    "#identifying columns   \n",
    "for item in names:\n",
    "    uniqueVals = df[item].unique()\n",
    "    print(item+\": \")\n",
    "    print(uniqueVals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e290f0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "unacc    968\n",
       "acc      307\n",
       "good      55\n",
       "vgood     52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_types = df.columns.values[-1]\n",
    "df[class_types].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9acdf9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/qn955ywj1qv363mbrl31qzc00000gn/T/ipykernel_34170/609437354.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_en = df_en.replace({True: 1, False: 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>doors_4</th>\n",
       "      <th>doors_5more</th>\n",
       "      <th>persons_4</th>\n",
       "      <th>persons_more</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_low  buying_med  buying_vhigh  maint_low  maint_med  maint_vhigh  \\\n",
       "0           0           1             0          0          1            0   \n",
       "1           0           1             0          0          0            0   \n",
       "2           1           0             0          0          0            0   \n",
       "3           0           1             0          1          0            0   \n",
       "4           0           0             1          1          0            0   \n",
       "\n",
       "   doors_3  doors_4  doors_5more  persons_4  persons_more  lug_boot_med  \\\n",
       "0        1        0            0          1             0             1   \n",
       "1        1        0            0          0             0             0   \n",
       "2        0        0            1          0             1             0   \n",
       "3        0        0            0          1             0             1   \n",
       "4        1        0            0          0             0             0   \n",
       "\n",
       "   lug_boot_small  safety_low  safety_med  class  \n",
       "0               0           0           1      1  \n",
       "1               1           0           1      0  \n",
       "2               1           0           1      1  \n",
       "3               0           0           0      2  \n",
       "4               1           0           0      0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode into numbers for model\n",
    "\n",
    "df_en = pd.get_dummies(df, columns=names, drop_first=True)\n",
    "df_en = df_en.replace({True: 1, False: 0})\n",
    "class_mapping = {\"unacc\": 0,\n",
    "                 \"acc\": 1,\n",
    "                 \"good\": 2,\n",
    "                 \"vgood\": 3}\n",
    "df_en['class'] = df_en['class'].map(class_mapping)\n",
    "\n",
    "class_col = df_en['class']\n",
    "df_en.drop(columns=['class'], inplace=True)\n",
    "last_col_pos = df_en.columns.get_loc('safety_med') + 1\n",
    "df_en.insert(last_col_pos, 'class', class_col)\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475287ca",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "- ... to be updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d86d3b80-a73e-4649-a93a-a22ae9b66243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Prepare training data\\nX = df_en.drop(columns=[\"class\"])  # Features\\ny = df_en[\"class\"]                 # Target\\n\\n# Train Gradient Boosting model\\nbest_gb_clf = GradientBoostingClassifier(\\n    learning_rate=0.1,\\n    max_depth=3,\\n    n_estimators=700,\\n    subsample=1.0,\\n    random_state=42\\n)\\nbest_gb_clf.fit(X, y)\\n\\n# Process test dataset\\nif \\'df_test\\' in globals():\\n    test_ids = df_test[\"id\"]  # Preserve test IDs\\n    X_test = pd.get_dummies(df_test.drop(columns=[\"id\"]), columns=names, drop_first=True)\\n    \\n    # Ensure all features match the training set\\n    missing_cols = set(X.columns) - set(X_test.columns)\\n    for col in missing_cols:\\n        X_test[col] = 0  # Add missing columns with default value 0\\n    \\n    X_test = X_test[X.columns]  # Reorder columns to match training data\\n\\n    # Predict on the test data\\n    test_preds = best_gb_clf.predict(X_test)\\n\\n    # Convert numerical predictions back to original class labels\\n    reverse_class_mapping = {0: \"unacc\", 1: \"acc\", 2: \"good\", 3: \"vgood\"}\\n    test_preds = [reverse_class_mapping[pred] for pred in test_preds]\\n\\n    # Create submission file with correct format\\n    submission = pd.DataFrame({\"id\": test_ids, \"output\": test_preds})\\n    submission.to_csv(\"submission.csv\", index=False)\\n    print(\"Submission file saved as submission.csv\")\\n\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Prepare training data\n",
    "X = df_en.drop(columns=[\"class\"])  # Features\n",
    "y = df_en[\"class\"]                 # Target\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "best_gb_clf = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=700,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "best_gb_clf.fit(X, y)\n",
    "\n",
    "# Process test dataset\n",
    "if 'df_test' in globals():\n",
    "    test_ids = df_test[\"id\"]  # Preserve test IDs\n",
    "    X_test = pd.get_dummies(df_test.drop(columns=[\"id\"]), columns=names, drop_first=True)\n",
    "    \n",
    "    # Ensure all features match the training set\n",
    "    missing_cols = set(X.columns) - set(X_test.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test[col] = 0  # Add missing columns with default value 0\n",
    "    \n",
    "    X_test = X_test[X.columns]  # Reorder columns to match training data\n",
    "\n",
    "    # Predict on the test data\n",
    "    test_preds = best_gb_clf.predict(X_test)\n",
    "\n",
    "    # Convert numerical predictions back to original class labels\n",
    "    reverse_class_mapping = {0: \"unacc\", 1: \"acc\", 2: \"good\", 3: \"vgood\"}\n",
    "    test_preds = [reverse_class_mapping[pred] for pred in test_preds]\n",
    "\n",
    "    # Create submission file with correct format\n",
    "    submission = pd.DataFrame({\"id\": test_ids, \"output\": test_preds})\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Submission file saved as submission.csv\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2c3a6e5-03a1-4e5b-a9e0-31f39f5748ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.3s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.3s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.7s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   7.4s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=5, n_estimators=600, subsample=0.8; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   5.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   6.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.9; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   4.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   3.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.9; total time=   8.3s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   5.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.2s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=600, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.8s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   7.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.2s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.8s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=10, n_estimators=2000, subsample=0.9; total time=   8.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   6.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   6.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=0.8; total time=   5.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  34.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.3s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  35.3s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.4s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  37.0s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.8s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=  10.8s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=  10.5s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=  10.9s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=5, min_samples_split=10, n_estimators=2000, subsample=0.8; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  11.1s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=   9.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=   9.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=   9.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  37.2s\n",
      "[CV] END learning_rate=0.01, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=2000, subsample=0.9; total time=  36.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=3, min_samples_split=2, n_estimators=600, subsample=0.9; total time=  10.2s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.8s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.3s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.8s\n",
      "[CV] END learning_rate=0.08, max_depth=7, min_samples_leaf=3, min_samples_split=5, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.0s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.9s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   8.1s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  11.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  11.3s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.4s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  11.4s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=1.0; total time=  11.2s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=  10.2s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.9s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.08, max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=2000, subsample=0.8; total time=   9.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=600, subsample=1.0; total time=   6.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.0s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.2s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.5s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   7.1s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.6s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   6.7s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   5.4s\n",
      "[CV] END learning_rate=0.08, max_depth=5, min_samples_leaf=3, min_samples_split=5, n_estimators=600, subsample=0.9; total time=   5.4s\n",
      "Best Parameters for Gradient Boosting: {'subsample': 0.8, 'n_estimators': 2000, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_depth': 3, 'learning_rate': 0.08}\n",
      "Validation Accuracy: 1.0000\n",
      "Stacked Classifier CV Accuracy: 0.9747 ± 0.0079\n"
     ]
    }
   ],
   "source": [
    "# Assume df_en is your one-hot encoded DataFrame with a 'class' target column.\n",
    "X = df_en.drop(columns=[\"class\"])  # Features\n",
    "y = df_en[\"class\"]  # Target\n",
    "\n",
    "# Split data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "#Fine tuning extra trees classifiers\n",
    "\n",
    "# Set up the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Extra Trees Classifier (More randomness, reduces overfitting)\n",
    "\n",
    "\n",
    "#    n_estimators=1000,\n",
    "  #  max_depth=None,\n",
    " #   min_samples_split=5,\n",
    "  #  min_samples_leaf=2,\n",
    "  #  random_state=42,\n",
    "  #  n_jobs=-1\n",
    "\n",
    "# Instantiate and fit the grid search\n",
    "grid = GridSearchCV(\n",
    "    ExtraTreesClassifier(), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#best model for Extra Trees\n",
    "et_clf = grid.best_estimator_\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "\n",
    "# Gradient Boosting with RandomizedSearchCV for better hyperparameter tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [600, 1000, 2000],\n",
    "    'learning_rate': [0.08, 0.05, 0.01],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Try 20 different settings\n",
    "    cv=10,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train) # Trains the Gradient Boosting Model using random combos of hyperparameters defined in param_dist\n",
    "best_params = random_search.best_params_\n",
    "gb_clf = random_search.best_estimator_ # best model for gradient boosting\n",
    "print(\"Best Parameters for Gradient Boosting:\", best_params)\n",
    "\n",
    "\n",
    "# Stacking Classifier (Combines multiple models for better accuracy)\n",
    "stacked_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('et', et_clf),\n",
    "        ('gb', gb_clf),\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train stacked classifier\n",
    "stacked_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_preds = stacked_clf.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "scores = cross_val_score(stacked_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Stacked Classifier CV Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095fb18-9248-4533-aca2-12fe2d1b4c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
