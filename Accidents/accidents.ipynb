{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e799011-1b37-4173-b5a7-8b0585fbe378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9p/37r_bxzx43lbmnmjw0dvtfx00000gn/T/ipykernel_9616/3644715177.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/9p/37r_bxzx43lbmnmjw0dvtfx00000gn/T/ipykernel_9616/3644715177.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# -------------------------\n",
    "# Data Preprocessing for Binary Classification\n",
    "# -------------------------\n",
    "\n",
    "# Define only the essential columns (including the target \"Class\")\n",
    "cols_to_keep = [\n",
    "    \"Severity\", \"Start_Lat\", \"Start_Lng\", \"End_Lat\", \"End_Lng\", \"Timezone\", \"County\", \"State\", \"Airport_Code\",\n",
    "    \"Temperature(F)\", \"Wind_Chill(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \"Wind_Speed(mph)\", \"Precipitation(in)\",\n",
    "    \"Weather_Condition\", \"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\", \"Stop\",\n",
    "    \"Traffic_Calming\", \"Traffic_Signal\", \"Sunrise_Sunset\", \"Civil_Twilight\", \"Nautical_Twilight\", \"Astronomical_Twilight\",\n",
    "    \"Class\"  # Target column\n",
    "]\n",
    "\n",
    "# Load the dataset using only the selected columns\n",
    "df = pd.read_csv(\"Classifying_accidents-train.csv\", usecols=cols_to_keep)\n",
    "\n",
    "# Convert boolean features to integers\n",
    "bool_cols = [\"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\", \"Stop\", \n",
    "             \"Traffic_Calming\", \"Traffic_Signal\"]\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "# Convert categorical features to numeric using Label Encoding\n",
    "categorical_cols = [\"Timezone\", \"County\", \"State\", \"Airport_Code\", \"Weather_Condition\", \"Sunrise_Sunset\", \n",
    "                    \"Civil_Twilight\", \"Nautical_Twilight\", \"Astronomical_Twilight\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)  # Ensure all values are strings\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # Store encoder for future use\n",
    "\n",
    "# Handle missing values by filling numeric columns with the median\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in [np.float64, np.int64]:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Convert target variable \"Class\" to binary values\n",
    "if df[\"Class\"].dtype == object:\n",
    "    unique_classes = df[\"Class\"].unique()\n",
    "    mapping = {unique_classes[0]: 0, unique_classes[1]: 1} if len(unique_classes) == 2 else {cls: i for i, cls in enumerate(unique_classes)}\n",
    "    df[\"Class\"] = df[\"Class\"].map(mapping)\n",
    "\n",
    "# -------------------------\n",
    "# Model Training (80/20 Rule for Train-Test Split)\n",
    "# -------------------------\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#print(\"\\nRandom Forest Classifier Accuracy:\", accuracy)\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3ef1e2-02c5-4fc8-8db6-c30a63ffc941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nRandom Forest Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb289def",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Step 1: Load & Preprocess Training Data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifying_accidents-train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Drop non-informative columns\u001b[39;00m\n\u001b[1;32m     17\u001b[0m drop_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZipcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeather_Timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Load & Preprocess Training Data\n",
    "# -------------------------\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"Classifying_accidents-train.csv\")\n",
    "\n",
    "# Drop non-informative columns\n",
    "drop_cols = [\"ID\", \"Street\", \"City\", \"Zipcode\", \"Country\", \"Weather_Timestamp\"]\n",
    "train_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# Convert boolean features to integers\n",
    "bool_cols = [\"Amenity\", \"Bump\", \"Crossing\", \"Give_Way\", \"Junction\", \"No_Exit\",\n",
    "             \"Railway\", \"Roundabout\", \"Station\", \"Stop\", \"Traffic_Calming\", \n",
    "             \"Traffic_Signal\", \"Turning_Loop\"]\n",
    "train_df[bool_cols] = train_df[bool_cols].astype(int)\n",
    "\n",
    "# Convert categorical features to numeric using Label Encoding\n",
    "categorical_cols = [\"State\", \"County\", \"Timezone\", \"Airport_Code\", \"Wind_Direction\",\n",
    "                    \"Weather_Condition\", \"Sunrise_Sunset\", \"Civil_Twilight\", \n",
    "                    \"Nautical_Twilight\", \"Astronomical_Twilight\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    train_df[col] = train_df[col].astype(str)  # Ensure all values are strings\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    label_encoders[col] = le  # Store encoder for later use in test data\n",
    "\n",
    "# Handle missing values\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype in [np.float64, np.int64]:  # Numeric columns\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "    else:  # Categorical columns\n",
    "        mode_val = train_df[col].mode()[0]\n",
    "        train_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Process target variable: Map \"Source1\" -> 0 and \"Source2\" -> 1\n",
    "train_df[\"Class\"] = train_df[\"Class\"].map({\"Source1\": 0, \"Source2\": 1})\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: Balance the Training Data\n",
    "# -------------------------\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nBefore balancing:\")\n",
    "print(train_df[\"Class\"].value_counts())\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train_df[train_df[\"Class\"] == 0]\n",
    "df_minority = train_df[train_df[\"Class\"] == 1]\n",
    "\n",
    "# Downsample the majority class to match the minority class size\n",
    "df_majority_downsampled = resample(df_majority, replace=False,\n",
    "                                   n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "# Combine the downsampled majority class with the minority class\n",
    "train_balanced = pd.concat([df_majority_downsampled, df_minority]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(train_balanced[\"Class\"].value_counts())\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Model Training\n",
    "# -------------------------\n",
    "\n",
    "# Extract features and target\n",
    "X_balanced = train_balanced.drop(columns=[\"Class\"])\n",
    "y_balanced = train_balanced[\"Class\"]\n",
    "\n",
    "# Split into training (80%) and validation (20%) sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Load & Preprocess Test Data\n",
    "# -------------------------\n",
    "\n",
    "test_df = pd.read_csv(\"Classifying_accidents - test.csv\")\n",
    "\n",
    "# Drop unnecessary columns (ensure 'ID' is kept for submission)\n",
    "drop_cols = [\"Street\", \"City\", \"Zipcode\", \"Country\", \"Weather_Timestamp\"]\n",
    "test_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# Convert boolean features to integers\n",
    "test_df[bool_cols] = test_df[bool_cols].astype(int)\n",
    "\n",
    "# Apply the same label encoding to categorical features as training data\n",
    "for col in categorical_cols:\n",
    "    test_df[col] = test_df[col].astype(str)  # Ensure all values are strings\n",
    "    test_df[col] = label_encoders[col].transform(test_df[col])\n",
    "\n",
    "# Handle missing values in test data (same strategy as training)\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].dtype in [np.float64, np.int64]:  # Numeric columns\n",
    "        median_val = test_df[col].median()\n",
    "        test_df[col].fillna(median_val, inplace=True)\n",
    "    else:  # Categorical columns\n",
    "        mode_val = test_df[col].mode()[0]\n",
    "        test_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Extract features for prediction\n",
    "X_test = test_df.drop(columns=[\"ID\"])\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],  # Ensure 'ID' is preserved for submission\n",
    "    \"Source\": test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"\\nSubmission file saved as 'submission.csv'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    2162816\n",
      "1    1652686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"Class\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
